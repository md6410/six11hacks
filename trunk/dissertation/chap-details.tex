\chapter{Sketch It, Make It: Details}
\label{sec:details}

The previous chapter gave an overview of SIMI's architecture,
including an introduction of SIMI's recognition process.
(Section~\ref{sec:recognition-architecture}). This chapter gives
details on how each recognizer works.

First, SIMI's corner finding and segmentation strategy is
described. This process is necessary to most recognition, and is what
produces geometric output like lines and arcs. Next, the three types
of recognizers are described: including Dynamic, Pen Up, and Deferred
recognizers. All sketch based interaction techniques are detailed in
these sections.

\section{Ink Parsing}
\label{sec:corner-finder}

Ink parsing is the process of identifying useful characteristics of
freehand digital input, hereafter referred to as `raw ink', `rough
ink', or simply `ink'. Characteristics include the locations of
corners, curvature at specific points, and the likely identities of
segments like lines or curves. Raw ink points are recorded as $(x, y,
t)$ coordinates that specify where a point is and it was created.

In the following sections, there are two different ways to measure
distance: Euclidean and Curvilinear (see
Figure~\ref{fig:distance-measures}). Euclidean distance is the
measurement most people are familiar with: this is how far apart two
points are on the 2D plane. Curvilinear distance follows the ink
stroke path. In the figure, points A and B are close together in the
Euclidean sense, but are farther apart in the Curvilinear sense. The
Euclidean and Curvilinear midpoints are also depicted in
Figure~\ref{fig:distance-measures}. 

\input{fig-distance-measures.tex}

SIMI's ink parsing strategy is simpler than many other approaches
found in literature on sketch-based interfaces and modeling
(SBIM). Others, like the strategies taken by
Sezgin~\cite{sezgin-early-processing} or Wolin~\cite{wolin-smr},
combine both \textit{time} and \textit{curvature} information when
corner finding. SIMI's approach for corner-finding relies only on
curvature, but still achieves good results.

When the user completes a stroke, the ink parser is invoked. First it
assigns a curvature value to each point. Next, a corner finder uses
this data to identify which (if any) points along the stroke are
corners. Last, the system analyzes the regions between corners to
determine the most likely segment type. The output of this process is
the set of segments formed in the last step. I will detail each of
these steps now.

\subsection{Curvature}

\input{fig-curvature-diagram.tex}

Figure~\ref{fig:curvature-diagram} illustrates how curvature is
calculated. A raw ink stroke is composed of a series of unevenly
distributed points. Sometimes, points may be very close together (as
when the user draws slowly). To determine the curvature at an
individual point, the algorithm uses a surrounding region called a
\textit{window}, rather than only the immediate neighbors. Without
this window, the curvature would be unreliable when points are very
close together.

The window's size $w$ is measured in pixels, and is determined by the
current zoom factor. When the zoom factor is 1 (meaning there is a 1:1
ratio between model and screen coordinates), the window size is
20px. To calculate the window boundaries at point $p_i$, the corner
finder begins at $p_i$ and traverses the stroke backwards and forwards
by half the window size $(w/2)$. It computes interpolated points $w_a$
and $w_b$ that are exactly $w/2$ units along the stroke to $p_i$. It
then forms two vectors: $v_a$ from $w_a$ to $p_i$, and $v_b$ from
$p_i$ to $w_b$. Note that all distances in this part are measured with
Curvilinear reckoning.

The signed curvature $\theta$ for $p_i$ is computed directly from
these two vectors. The magnitude is determined by their dot product;
the sign is determined by the cross product.

\begin{samepage}
\begin{equation}
  \theta_{unsigned} = \arccos \frac{v_a\cdot v_b}{|v_a| |v_b|}
\end{equation}

\begin{equation}
  \theta = \left\{ 
  \begin{array}{r l}
    \theta_{unsigned} & \quad \text{if } v_a \times v_b \geq 0\text{,}\\
    -\theta_{unsigned} & \quad \text{otherwise}\\
  \end{array} \right .
\end{equation}
\end{samepage}

It is tempting to use $\arctan$ to calculate curvature because it is a
simple calculation. However, this leads to discontinuities when the
vertical change is zero. The approach described above is valid for any
orientation.

\subsection{Isolate Corners}

Now that each point's curvature has been calculated, we can identify
corners. This is a two-step process illustrated
in~Figure~\ref{fig:corner-finding}. First, clusters of high curvature
are identified. To be a member of such a cluster, the absolute value
of a point's curvature must be greater than some threshold. In the
current version of SIMI this value is 45 degrees.

\input{fig-corner-finding.tex}

Once clusters have been computed, a corner is found for each. A
cluster's corner is simply the point closest to the curvilinear
middle. In other words, if the distance along stroke from the
beginning to the end of the cluster is 9, the corner is the point in
the cluster that is nearest to the interpolated point 4.5 units from
the cluster beginning.

In addition to the corners discover in this process, the stroke's
first and last points are also included as `corners'. This is for the
convenience of the next step where segments are identified.

\subsection{Identify Segment Types}

The last step in ink parsing is to identify segment
types. Table~\ref{tab:segment-types} in the previous chapter describes
the possible segment types. For each segment type there is a
corresponding segment finder. The segment finders for `open' types
(Line, Arc, Spline) operate on regions between corners. The remaining
segment finders are identified by examining the raw ink directly, and
do not use corner data.

Like semantic sketch recognizers, it is possible for multiple segment
finders to positively identify ink---e.g. a segment might be an arc,
or it might be a line. To mitigate this, segment finders operate on a
priority system. The priority is: Dot, Circle, Ellipse, Blob, Line,
Arc, and Spline. In other words, if the Dot finder identifies a dot,
there is no possibility of the associated ink being identified as a
Circle.

\subsubsection{Dot Finder}

The dot finder examines the entire ink stroke. If the entire stroke
was made in less than some threshold value (currently 180
milliseconds), it is always considered a dot. Otherwise, it continues
by computing the convex hull of all stroke points. Two properties of
the hull are used next: the area and the aspect ratio. If the ratio
defined by $ratio = area/aspect$ is less than 120, it is a dot. If
not, there is one final check to make. The stroke's point density is
computed. This is the number of points in the original ink stroke,
divided by the hull's area. If $ratio/(0.3 + density)$ is less than
120, it is a dot.

\subsubsection{Circle and Ellipse Finder}

Circles, Ellipses, and (in the next part) Blobs are the three
\textit{closed} segment types. A segment is closed if the beginning and
end points are close, relative to the overall length of the
stroke. More formally given start and end points $p_{start}$ and
$p_{end}$:

\begin{equation}
\begin{array}{rcl}
closeness &
= &
\dfrac{EuclidianDistance(p_{start}, p_{end})}{CurvilinearDistance(p_{start}, p_{end})} &
\\
closed &
= &
\left\{ 
  \begin{array}{r l}
    true & \quad \text{if } closeness \leq .1\text{,}\\
    false & \quad \text{otherwise}\\
  \end{array} \\ %\right\} \\
\end{array}
\label{eqn:ellipse}
\end{equation}

Circles and Ellipses are identified with the same finder. If the input
stroke is closed, the input is fit to an ellipse. To avoid placing
restrictions on how users draw, they may draw ellipses at arbitrary
angles. SIMI implements a least squares approach described by
Fitzgibbon \textit{et. al}~\cite{fitzgibbon-ellipse-fitting}. It is an
efficient algorithm whose complexity grows linearly with the size of
the input. The output of the ellipse fitting algorithm is a rotated
ellipse, defined by a centroid, a rotation, and major and minor axis
magnitudes.

An error value is calculated to determine how closely the raw input
matches the derived ellipse. This is done in a modified \textit{least
  squares} fashion that requires the calculating the minimum distance
between a point and the ellipse. Unfortunately this is an involved
process (for example, see ~\cite{eberly-point-to-ellipse}). SIMI
approximates the shortest distance between a point $p$ and an ellipse
by discretizing the ellipse boundary into a list of points $d$, and
computes the minimum distance between $p$ and $d$.

The error value measuring the closeness between raw input points $p_i,
i \in [0..n)$ and the discretized elliptical surface $D$ is given with
  the equation:

\begin{equation}
Elliptical\:Error = \frac{
\sqrt{
\sum min^2(p_i, D)
}
}{
n-2
}
\end{equation}

In order for the input to be considered a Circle or Ellipse, the total
error must be less than 1.0. This value was determined experimentally,
given a discretization of 60 points. To distinguish between a Circle
and an Ellipse, the fit ellipse's eccentricity used. Eccentricity
describes how flattened the ellipse is as defined by its major and
minor radii:

\begin{equation}
Eccentricity = \sqrt{\dfrac{major^2-minor^2}{major^2}}
\end{equation}

If the eccentricity is less than 0.7, the input is a Circle; otherwise
it is an Ellipse.

\subsubsection{Blob Finder}

A \textit{Blob} is a spline than wraps around on itself to form a
closed loop. Recall that SIMI identifies a closed shape when a
stroke's start and end points are close relative to stroke length (as
given by Equation~\ref{eqn:ellipse}). To transform rough input into a
smooth shape, additional processing is necessary because the start and
end of the stroke are discontinuous.

\input{fig-blob.tex}

There are two possible situations: there is a \textit{gap} between the
stroke's start and end, or there is an \textit{overlap}. These cases
are illustrated in Figure~\ref{fig:blob}. The Blob Finder identifies a
gap when the first point $p_0$ is closer to the last point $p_{n-1}$
than it is to the last point's neighbors $p_{n-i}$, where i is in the
range $[2..10]$. An overlap is when $p_0$ is closer to one of the
$p_{n-i}$ points.

In case of a gap, the next action is simple: the first and last points
are connected. When an overlap is detected, the algorithm removes
points from the end of the stroke until there is no overlap
(e.g. there is a gap). Then the Blob's start and end are connected as
before.

The control points for Blob and Spline types are computed and stored
in the same manner. This representation is discussed in the Spline
section.

\subsubsection{Line Finder}

Lines are typically the most common segment type. Like arcs and
splines, lines are an open segment type. A single ink stroke may
contain any number of open segment types. All open segment type
finders operate on regions between (and including) corners---they do
\textit{not} operate on the entire stroke, unless the stroke happens
to contain no corners.

The line finder fits a region of points to an idealized line, and
measure its error. If the error is below some threshold, it reports a
positive result. The idealized line begins and ends at the corners on
either side of the region. A raw point's individual error is
calculated as the shortest (orthogonal) distance between the point and
the idealized line. The total error for the region is:

\begin{equation}
Line\:Error = \dfrac{\sqrt{\sum OrthoDistance^2(p_i, line)}}{n-2}
\end{equation}

If the error is below the threshold (currently 1.5), the region is
identified as a line segment.

\subsubsection{Arc Finder}

Arcs in SIMI are portions of ellipses. If a region is not a line, the
Arc Finder attempts to identify an elliptical arc. It does this by
using the same math as Ellipse shapes, including the error metric in
Equation~\ref{eqn:ellipse}. If the total error is less than 0.5, the
region is identified as an elliptical arc.

Note that the arc is only a portion of the ellipse. The portion is
recorded using the start and end angles, and (to determine which
direction the arc traverses the ellipse) a median angle.

\subsubsection{Spline Finder}

Splines are the fall-back segment type: if nothing else fits, a region
is classified as a spline. SIMI uses natural cubic splines to render
these curves.

As mentioned earlier, Blobs are modeled in the same way as
Splines. Both variations are composed of two primary points $A$ and
$B$ (for splines, the start and end points; for blobs, the start point
and initial centroid point). Using these two points, a third point $C$
is found by rotating $B$ about $A$ by 90 degrees. These three points
form the basis for a barycentric coordinate system that identify
locations of the Spline/Blob's control points. This way, when $A$ or
$B$ move, the control point locations are easily recalculated.

A control point is defined with a pair of numbers: one in the
$A\rightarrow B$ direction, another in the $A\rightarrow C$
direction. A value of one indicates full movement from the start to
end point.

\input{fig-spline-control-points.tex}

\section{Dynamic Recognizers}

As mentioned in \ref{sec:overview-dynamic-recognizers}, Dynamic
recognizers attempt to identify gestures as the pen is down. In order
to maintain a responsive user interface, these recognizers must
execute very quickly because they are invoked at high frequency. When
any dynamic recognizer has a positive result, the others are
suppressed until the next stroke. They each give distinct graphic
feedback to let the user know that the recognizer has triggered.

\subsection{Erase}

The \textit{Erase} gesture allows the user to delete segments. It lets
users recover from errors or lets them change their minds. Unlike Undo
(discussed below), Erase gives access to any line work in the
model. Erase can also be used as part of a deliberate process, for
example to cut away segments to create notches (as
in~\cite{zeleznik-lineogrammer}).

\input{fig-erase.tex}

SIMI users depend on being able to erase quickly and easily. While it
may seem that an efficient and easy to use gesture recognizer would be
easy to write, this is not the case. During development, the Erase
gesture went through a number of design iterations. Initially, it was
implemented as a Deferred recognizer (executing after the pen was
lifted). Users were only able to successfully execute the gesture
about half the time. When it failed, the scribble was interpreted as
line work, requiring users to erase or undo the unwanted line work. This
was a common and frustrating event. The recognition algorithm was only
part of the problem. Proper visual feedback was also a necessary part
of the solution.

Erase was reimplemented as a dynamic recognizer so it would operate as
the pen was down. It identifies erase gestures in mid-stroke, showing
a colored 'X', indicating the user's erasure will succeed. This gives
users confidence the system understood, and reduces the number of
recognition errors substantially.

The dynamic erase gesture is implemented as follows. It involves
several parameters that may be tuned for different
circumstances. These parameters are summarized in
Table~\ref{tab:erase-params} after the description.

First we assign each point $P_i$ with a time stamp $T_i$, a path
distance $D_i$, and a heading vector $H_i$. Path distance is measured
as the curvilinear length from the initial point: $D_0=0$, and the
rest are $D_i = D_{i-1} + distance(P_{i-1}, P_i)$.

The heading $H_i$ is a normalized vector from $P_{i-k}$ to $P_{i+k}$,
using a window size $k$. The first $k$ points use $H_k$ for their
heading.

Next we add points to a list of sample points $S$. If the path
distance between $D_i$ and the most recently added sample point is
greater than $min_{sd}$, $P_i$ is added to $S$. When a new sample
point is added, a sub-list $R$ is assembled containing recent sample
points that occurred within $t$ milliseconds. If the angle between the
new sample point's heading and any point heading in $R$ is greater
than some angle threshold value $min_\theta$ (we use $\pi$ radians),
it increments a `corner' count value for the current pen stroke. 

When more than $min_c$ corners are found in a stroke, the stroke is a
strong candidate to be interpreted as an erase. When the corner count
has reached $min_c$, the system checks to see if the input resembles a
circle. This final check is necessary to avoid confusing a latch
gesture as an erase gesture.

If the circle check fails, the stroke is interpreted as an
erasure. The system provides visual feedback to alert the user that
the gesture has been recognized and halts recognition until the pen is
lifted.

Because the sample list depends on a relatively short duration, the
user must scribble vigorously to activate the erase gesture. Erasing
is a destructive process. Even though the Undo command lets the user
quickly recover from an unwanted erasure, they are nonetheless
disconcerting. Scribbling vigorously helps to avoid false positives.

When the user lifts the pen after successfully issuing an erasure,
SIMI determines which (if any) segments should be removed from the
model. The simplest approach would be to identify any segment that
intersects the erase gesture's convex hull. However, this leads to
poor results because users often want to erase items that are near
other items that should be kept. If this strategy were applied, both
the line and the arc in Figure~\ref{fig:erase-basic} would be erased.

When activating an erasure, the first step is to collect all the
segments that are under the erase gesture's convex hull. Next, SIMI
calculates the percentage of each segment's length that is under the
hull.

It is common that users would like to erase several items with the
same gesture. To support this, SIMI chooses the segment that has the
highest percentage and any segment whose coverage is at least $C\%$ of
that value. In Figure~\ref{fig:erase-basic} about 10\% of the line is
under the hull, while about 50\% of the arc is. In the current version
of SIMI, $C=70$, so any segment that is at least 70\% of 50 (in other
words, 35\%) would be erased. Since the line is only 10\% under the
hull, it remains.

This set of segments are then removed from the model. Further, any
constraints that are no longer relevant are also removed.

\input{tab-erase-params.tex}

\subsection{Undo and Redo}

There is very little \textit{recognition} involved with SIMI's
\textit{Undo/Redo} recognizer. The user presses the button with their
non-dominant hand and then drags the stylus left (to undo) or right
(to redo). It is the only technique that can not be performed entirely
with the pen. While it might not require recognition like the others,
it does have to fit into the same framework.

The undo/redo events are triggered with each 40 pixel change in
the~$x$ dimension. Each event shows a preview of what the model looked
like at some point in time. Releasing the external button commits the
change by replacing the current state with the previewed state. The
user may lift the pen, reposition their hand, and continue
gesturing. This allows the user to smoothly `scrub' through their
model's design history. Each `page' in SIMI's user interface has a
separate design history.

Each state in the design history stores a complete snapshot of the
model (containing points, segments, constraints, and cutouts) as well
as a cached graphic. This is a fast memory-intensive strategy that
requires only minimal computation. Snapshots are made when the user
adds, modifies, or removes geometry or constraints.

\subsection{Flow Selection}

\input{fig-flow-selection.tex}

\textit{Flow selection} is a time-based selection and operation
technique that lets users deform \textit{regions} of curved
segments~\cite{johnson-flow-selection}. It is useful for fixing
errors, or simply playing with curves to achieve an esthetically
pleasing effect.

Flow selection is triggered by holding the pen still for a brief
period (e.g. 800 milliseconds). Once triggered, it begins selecting
points on segment nearest the stylus (see
Figure~\ref{fig:flow-selection-example}). The selection slowly grows
along the curve, as its points begins to `heat up' near the
stylus. The longer the pen is held down, the more strongly points are
selected (e.g. they become `hotter'), and the selection size gets
bigger. Next, the user can move the stylus without lifting. This moves
selected points---the more strongly selected, the more they move. The
process is illustrated by the finite state machine in
Figure~\ref{fig:flow-selection-fsm}.

Flow selection is graphically presented by highlighting the affected
region. Points that have positive selection strength are drawn as
small white dots, and the line work connecting them is drawn in a shade
of red. The stronger the surrounding points, the brighter red the
curve is drawn.

\section{Pen Up Recognizers}

If no dynamic recognizer claimed a user's stroke, the \textit{Pen Up}
recognizers are invoked. There are two pre-processing steps before
this happens. The first is Ink Parsing---corner finding and segment
identification. This was discussed at length earlier in the
chapter. The Pen Up recognizers have access to both the structured
data including corners and segment types, as well as the original raw
data. The second pre-processing step is called \textit{hook removal}.

\subsection{Removing Hooks}

A \textit{hook} is a short region of ink made accidentally as the user
presses down or lifts the stylus from the digitizing tablet. Many
tablet surfaces are smooth, so there is little frictional resistance
to prevent this from happening. Unless hooks are removed, they
frustrate recognition efforts. Hook removal is shown in
Figure~\ref{fig:hooks}.

\input{fig-hooks.tex}

Hook removal occurs after ink parsing but before recognizers are
invoked. The hook remover receives a set of newly made segments. A
hook is a segment that has two properties: (a) it was made from ink
appearing at the beginning or end of the user's stroke, and (b) its
curvilinear length is less than 10\% of the longest segment from the
same ink stroke. Hooks are simply removed from the model and not
passed on for recognition.

\subsection{Latching}

\input{fig-latch.tex}

Users often want lines to meet at a common point. In the formative
work practices study, we observed Illustrator users struggling to make
lines co-terminate. Sometimes the designer would simply extend lines
past each other to ensure that the laser will correctly cut the
corner.

Latching is the process of adjusting adjacent segments to meet at a
common point~\cite{herot-latch-corners}. All line work in SIMI is
meant to compose cutouts, which are closed sequences of latched
segments. The designer must therefore be able to find and fix
non-latched segments to form cutouts. SIMI draws a red marker at
`lonely endpoints' (endpoints associated with only one segment) to
make it obvious when there is a latching opportunity.

SIMI will automatically latch segments (shown in
Figure~\ref{fig:latch}) under fairly conservative circumstances. Users
may also manually latch endpoints in three orientations
(Figures~\ref{fig:latch-endpoint}--\ref{fig:latch-tjunct}). Both
automatic and manual latching is performed as a result of a Pen Up
recognizer.

\subsubsection{Automatic Latching}

The automatic latching process examines line work for cases where the
user likely meant their segments to connect, and adjusts one or more
segments to meet. However, this can pose problems if it is too zealous
because users must erase or undo to recover, which interrupts the flow
of work. Therefore the automatic latcher is intentionally conservative
to avoid frustrating users.

The auto-latcher is \textit{not} activated with the Pen Up
recognizers---it is actually a Deferred recognizer. It is discussed
here because it is closely related to the manual latching techniques,
which are Pen Up recognizers.

The auto-latcher iterates through all newly made segments, and
compiles a list of those with lonely endpoints. For each lonely
endpoint, an \textit{endcap} formed. This is a short line segment
centered at the lonely point. The endcap length is X\% of its
associated segment (SIMI sets this parameter at 10\%). The endcap
orientation is tangent to the segment at the lonely point. They are
represented as the light blue shaded regions in
Figure~\ref{fig:latch-auto}.

The endcap length and orientation are parameterized in this way to
avoid latching segments that do not visually appear to meet. This
approach was inspired by the gestalt principle of common fate.

Next, each endcap is intersected with nearby endcaps from either new
or existing lonely point endcaps (with their own length and
orientations). When two endcaps intersect, the auto-latcher reports a
positive result, and the two related segments will merge. The merging
process is discussed below, after the manual latchers.

\subsubsection{Manual Latching}

There are three ways users manually latch segments together,
illustrated in Figure~\ref{fig:latch}. They are activated by the same
recognizer, but the action taken is distinguished by the particular
configuration of segments below the gesture.

The three kinds of manual latching are: \textit{endpoint},
\textit{continuation}, and \textit{T-Junction}, but the gesture (a
small lasso, discussed shortly) is the same for all of them. The
meaning of the latch gesture depends on what the user targets: in
other words, what elements are beneath the user's input? If the user
targets two endpoints, it is either an endpoint latch (when the two
segments are not close to the same orientation) or a continuation
latch (when they are about the same orientation). If the user targets
an endpoint and the mid-section of another segment, it is a
T-Junction.

The encircle gesture is recognized as follows. The gesture curvilinear
length must be less than a threshold (currently 200 px). This helps
distinguish line work (which tends to be large) from latch gestures
(which are small). Second, the input must be \textit{closed} using
logic similar to the closed segment type finders (e.g. Blob
Finder). In this context the input is closed if any of the last 10\%
of points were within 7 pixels of the initial point.

\subsubsection{Merging Segments}

\input{tab-latch.tex}

If either the automatic or manual latching algorithm found a positive
result, two segments must be merged. Table~\ref{tab:latch} summarizes
the inputs, where the merge occurs, and the results. In each case, two
segments are merged, but the output depends on the latch
type. Automatic and endpoint latching result in two segments that have
been joined at segment ends. Continuation latching results in a single
segment---the two original segments are replaced by one longer
one. With T-Junction latching, one segment is split in the interior
region into two segments, and the other segment is merged with them
where the split occurred.

Points and segments are created and destroyed in this process. This
must be reflected in the model. Any constraints that referenced a
deleted segment must be re-evaluated to see if (and which) new
segments apply. If constraints depend on segments that are removed,
the constraint is deleted.

\subsection{Pan and Zoom}

SIMI lets users control the view port. Tapping the pen twice displays
a pan/zoom widget shown in Figure~\ref{fig:panzoom}. To pan, drag
starting in the left square in any direction. To zoom, start in the
right square: up to zoom in, down to zoom out (the horizontal
dimension is not used). The controls disappear after two seconds of
non-use.

Many parameters used in other recognizers are sensitive to the zoom
factor. When the user zooms in or out, distance factors must change
accordingly because there is a disparity between physical and model
coordinate distances. For example, if the zoom factor is $2x$, the
latch gesture considers the input closed using $7/2=3.5$ model
units rather than $7$ as it would without zooming.

\input{fig-panzoom.tex}

\subsection{Select Points and Segments}

Users can move points by selecting and dragging them. To select a
point, users make a quickly made swirling gesture that is recognized
as a \textit{Dot} segment type. If the dot is made within 9 pixels of
a segment endpoint, the closest endpoint is chosen to be
selected. Once a point is selected, hovering the pen nearby shows a
hand cursor, letting the user know that dragging the stylus will move
the selected point.

Selected points can be de-selected by drawing a latch gesture around it
(discussed above). The point is de-selected if no latch recognizer
would have an effect.

Segments may be selected as part of the process to specify \text{Same
  Length} constraints. To select a segment, the user over-traces a
portion. It is not necessary to over-trace the entire segment. To
recognize a segment selection gesture, the system compares the rough
input with the segments nearby. To be a segment selection gesture, the
average orthogonal distance to the segment must be less than 5 px, the
maximum distance less than 15, and (for line segments) the orientation
must be within 20 degrees.

A selected segment is graphically with a thick blue line
weight. Additionally, the segment's length is displayed nearby. Users
deselect segments by over-tracing again.

Users establish \textit{specific length constraints} by selecting a
line segment and then \textit{typing} a value on the keyboard. This is
the only interaction technique the violates the guidelines of not
depending on the keyboard. It was necessary to implement to enable
users to make items with specific dimensions, which is a common
need. Ideally users would employ a pen-centric approach to set
specific length constraints via handwriting recognition. Because that
is an active and well-developed topic it was appropriate to focus
effort elsewhere.

\section{Deferred Recognizers}

The deferred recognizers activate after one of two events has occurred:
either the user has pressed the button with their non-drawing hand, or
there has not been stylus activity for a brief time period. Deferred
recognizers are invoked only on input that was not positively
identified by either Dynamic or Pen Up recognizers.

Like Pen Up recognizers, Deferred recognizers could operate on either
raw ink data or the set of segments found in Ink Parsing. However in
practice, the three recognizers in this category only use segment
data.

Unlike Pen Up recognizers, Deferred recognizers must be able to handle
several ink strokes. The input might be anything: line work, a
constraint, line work and constraints, two Same Length and two Right
Angle constraints, and so on. 

\input{fig-delayed-example.tex}

For example, consider the scenario pictured in
Figure~\ref{fig:fig-delayed-example} where the user draws a spline,
two right angles, and a Same Length gesture. The ink processor found
seven segments: the spline at top, and six short line segments in the
other strokes. Each recognizer receives these seven segments as input
and must identify as many instances of its type as it can. The Right
Angle recognizer, for example, looks for two short line segments of
approximately the same length that appear to meet at roughly a 90
degree angle.

Given this input set of $n=7$ strokes, the Right Angle recognizer has
$n^2=49$ possible pairings to examine. Each pairing has four possible
relative orientations. A recognizer that requires more segments has
vastly more combinations. This process is also fraught with subjective
noise: it looks for \textit{short} line segments of
\textit{approximately} the same length that \textit{appear} to meet at
\textit{roughly} 90 degrees. When finished, several recognizers may
claim segments that belong to other positive interpretations.

In sum, there are three main challenges in this situation: (1) the
search space is potentially very large, (2) subjective assessments
like \textit{approximately} must be made computable with numbers, and
(3) conflicting results must be mediated.

Alvarado addressed these problem in her thesis
work~\cite[Ch. 4]{alvarado-phd-thesis}. I have re-implemented her
approach to address the first two problems. It prunes the search space
considerably, and fixes the meaning of vague measurements. The third
problem---determining which interpretation is most likely---is handled
differently.

Recognition mediation in SIMI uses two processes to determine which is
correct. The first process ranks contending results by how relevant
they are in context. The next process is invoked only if the first is
inconclusive. Second is a list that ranks recognizers in order of most
to least common.

\subsection{Same Length}

The \textit{Same Length} gesture establishes a constraint that keeps
two or more line segments the same length. The exact value for this
length is not specified directly. Instead, the constraint computes the
average length and will attempt to lengthen or shorten line segments
to that length. Users may add segments to an existing Same Length
constraint, or combine two such constraints. 

\input{fig-same-length.tex}

Figure~\ref{fig:same-length} shows how the Same Length gesture is made
and how it can be used. In panel~\textit{\subref{fig:same-length-1}}
the user draws the gesture on two sides of a quadrilateral to make
those sides the same length. The Deferred recognizer identifies this,
and the system creates and enforces the Same Length constraint
(panel~\textit{\subref{fig:same-length-2}}. The user creates a second
constraint by waiting until the first has been recognized, and drawing
the gesture over the remaining lines of the quadrilateral
(panel~\textit{\subref{fig:same-length-3}}). Next the user decides to
combine these constraints by drawing a hash mark over one constrained
line from each existing Same Length constraint
(pane~\textit{\subref{fig:same-length-4}}). Panel~\textit{\subref{fig:same-length-5}}
shows the result. This shape could have been made in a single
recognition phase by hashing all four line segments. That would be
equivalent to the state shown in the last panel.

A Same Length gesture is recognized when it finds two or more short
input line segments $(in_0, in_1, ...)$ that cross corresponding
existing line segments $(S_0, S_1, ...)$. All input lines $in_i$ must
be at least 40\% the length of the longest one. In addition, each
$in_i$ must be within 30\% of $S_i$'s length to $S_i$'s
midpoint. Users tend to naturally follow these rules without prior
tutoring: the hash mark is a convention in pencil-and-paper sketching,
and it is consistent with the Same Length constraint's visual
appearance.

Graphically, any existing Same Length gesture is drawn as a set of
short red lines passing through the midpoint of each $S_i$ at a 45
degree angle (relative to $S_i$). Like other constraints, the
constraint is drawn in a brighter red when the stylus hovers
nearby. This serves two purposes. First, it reduces the visual clutter
of the whole screen. Second, it lets the user see which linework is
related to a single Same Length constraint. 

\subsection{Same Angle}

Designers can constrain angles to be the same. This is particularly
useful for creating symmetric parts. The gesture is the same as the
Same Length gesture, but the user draws the hash marks over line
segment intersections. A Same Angle constraint is indicated with a red
arc symbol near the related corners. In Figure~\ref{fig:same-angle},
the user has created a symmetric trapezoid. The pen hovers near the
upper left corner, so the visual feedback for the upper Same Angle
constraint is prominently displayed.

\input{fig-same-angle-symmetry.tex}

\subsection{Right Angle}

The Right Angle constraint allows designers to make 90 degree
angles. Right angles are one of the most common geometric features of
the artifacts surveyed in Section~\ref{sec:formative-artifact}. Right
angles are used to define not only the esthetic shape of a cutout, but
also for making joints for combining parts.

The gesture for making right angles looks like a half-square
symbol. It is commonly used in pencil-and-paper sketching. The Right
Angle recognizer looks for two short segments that meet at roughly a
right angle. 

The gesture can be made in one or two strokes. It does not require
users to draw these strokes in any particular way---only that the
result looks like a half-square. Once it identifies two line segments
that meet the requirements, corners are labeled as shown in
Figure~\ref{fig:right-angle} (left panel). This checks context around
the gesture to determine which (if any) lines the right angle applies
to.

The context check looks for nearby line segments that are in the
correct location and orientation to supports recognition of a right
angle constraint.  The following description uses tunable parameters
summarized in Table~\ref{tab:right-angle-params}.

The context check finds nearby lines $T_0$ and $T_1$ that share a
vertex and form an angle that is $90\pm\theta_0$ degrees. This
requirement might cause the system to miss the intended target, but it
also reduces the search space. If the user tries to constrain a line
pair that meets at an overly obtuse angle, they may move vertices
until they are approximately 90 degrees before applying the Right
Angle gesture.

The line pair's common vertex must be within $d$ pixels of corner $D$
(depicted in Figure~\ref{fig:right-angle}). The lines must also have
the appropriate position and orientation. Point $B$ must be within $d$
px of $T_0$, $C$ within $d$ px of $T_1$, and the angles formed by
$(T_0, line(AB))$ and $(T_1, line(AC))$ must be $90\pm\theta_1$ degrees.

\input{fig-right-angle.tex}
\input{tab-right-angle.tex}

The context checker reports one of three confidence levels for each
nearby line pair: \textit{Yes}, \textit{Maybe}, or \textit{No} (see
Fig.~\ref{fig:right-angle}). It reports \textit{Yes} if all
constraints hold, \textit{Maybe} if all but one hold, and \textit{No}
otherwise. If there is a tie (multiple Yes results, or multiple Maybes
when there is not a Yes result) the one whose $T_0$--$T_1$
intersection is closest to point $D$ is chosen.

