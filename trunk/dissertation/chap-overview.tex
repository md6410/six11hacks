\chapter{Sketch It, Make It: Overview}
\label{sec:overview}

The primary contribution of this thesis is the set of interaction
techniques implemented in a single design tool called Sketch It, Make
It (SIMI). SIMI is a modeling environment for laser cutter design that
recognizes short sequences of drawn input made with a stylus. Using
only freehand input, SIMI enables a designer to iteratively and
incrementally create precise laser cut models.

I am inspired by the potential of freehand drawing as the basis for
precision modeling for several reasons. Sketching is quick and can be
easily learned. It is simple and modeless: unlike structured editing
software, a designer need not set a pencil's mode to line, circle, or
anything else. I will show that given an appropriate set of
interaction methods, sketched input can provide enough information to
make a precise digital model.

There are several principles that guided SIMI's design and development.

\begin{itemize}
\item \textbf{Democratized design}: Freehand drawing is a skill that
  most people already have. It follows that a tool based on sketch
  based interaction should be usable by a majority of people. For this
  reason I target avocational designers, not professionals. 
\item \textbf{Sketch based}: The user should never feel obliged to set
  down their pen. In the past, many sketch based design tools have
  relied on keyboard input, or used interface widgets that are
  appropriate for mice but are uncomfortable to use with a stylus
  (e.g. hierarchic menus).
\item \textbf{Coherence of interaction techniques is key}: The tool
  presents a set of sketch based interaction techniques that work well
  together. Researchers commonly make toy systems that demonstrate one
  or two novel interaction techniques in isolation (e.g. my own prior
  work on Flow Selection~\cite{johnson-flow-selection}). But a useful
  tool has many individual techniques. The current system implements
  many techniques together to give an example of a way to make them
  work harmoniously.
\item \textbf{Useful and usable}: Last, the system lets people make
  real things in a real domain (namely, laser cut objects). The
  current implementation of the tool is efficient and highly
  responsive. In informal demonstrations, more than one person has
  noted that the system seems more like a commercial product than a
  research system. This is intentional.
\end{itemize}

\section{Rapid Fabrication and Laser Cutting}

Laser cutters are among the more common and affordable fabrication
machines. One can think of a laser cutter as a fast, strong, and
precise automated razor that cuts flat material (paper, wood, plastic,
textiles, etc.). 

\input{fig-laser-prices.tex}

The price of laser cutters is quickly declining, making it possible
that more people have access to them. Figure~\ref{fig:prices} shows
prices for a comparable~25-Watt,~16''x12'' laser cutter model from
Universal Laser Systems (these values were found on hobbyist web
forums). While these data may not be exact, they do show the price of
desktop laser cutting machines has been cut by almost half in the past
ten years. While still out of reach for most people to afford, they
are becoming inexpensive enough for schools and hacker spaces to own.

Laser cut designs are composed of parts cut from solid, flat material
and assembled in various ways: laminated, notched, bolted together,
\textit{etc}. Various materials require different laser speed and
intensity settings to achieve a quality cut. The designe uses a
software application to specify part shapes for laser cutting. The
software outputs vector graphics called a ``cut file'' that defines
these shapes. As most joints have small margins of error, lengths,
angles, and relative position must be specified precisely so that
parts fit together properly.

Tools for designing laser cut objects must allow users to precisely
specify dimensions. Like a physical saw, the laser leaves a gap in its
wake, called a \textit{kerf}, (between 0.2mm and 0.5mm on a 40 watt
cutter). This is an important consideration when designing facets
whose tolerances are small with respect to kerf. A notch joint, for
example, is ineffective if it is 0.1 mm too large or small.


\section{Motivating Scenario: Pictureframe Holder}

\input{fig-picture-frame.tex}

To introduce Sketch It, Make It I will explain how it could be used to
make the picture stand shown in Figure~\ref{fig:simi-example}. This
narrative helps explain the overall user experience while exposing
technical aspects (which are discussed in much greater detail in the
following chapter).

We begin with the idea of a stand with two horizontal rails as a base
and a five-part vertical support structure, joined with notches. Using
SIMI on a tablet device like the Wacom Cintiq shown in
Figure~\ref{fig:simi-intro}, we first draw the rough profile of the
vertical support piece using curved and straight segments. After a
brief period of inactivity, SIMI captures our drawing, straightening
lines, smoothing curves, and connecting curved and straight
segments. We may optionally press a button with our non-dominant hand
to ask SIMI to do this immediately. If we make a mistake (or if we
change our mind), we can recover quickly by scratching out the
unwanted ink, or use an Undo gesture.

After sketching the rough outlines of our two parts, we begin to
refine the design and make it precise.  We square the corners by
drawing right-angle braces (Figure~\ref{fig:motivating}a).  Now as we
adjust the shapes of the two parts by selecting and dragging endpoints
and re-shaping curves, SIMI maintains the right-angle constraints
we've established.
 
Next, we add notches to the two parts for the joints. We draw five
small notches on the base rail. For each notch we draw three lines
inside the outline of the part, and then use the erase gesture to
remove the residual outline segment (Figure~\ref{fig:motivating}b).
Then we indicate that both sides of the notch are to be the same
length: We draw tick marks on each segment, and right-angle braces to
keep the notch perpendicular to the edge of the part. The notches must
have exactly the right dimensions: too wide, the top parts will
wobble; too narrow and they will not fit. We size the notch by
overtracing its segments and entering fixed dimensions
(Figure~\ref{fig:motivating}c).
 
We drag the base part (twice) and the support part (five times) to
SIMI's cut file area to prepare a PDF file for cutting, and then send
it to the laser cutter.  Finally we assemble the cut parts to make the
picture stand in Figure~\ref{fig:simi-example}.

\input{fig-motivating-example.tex}

\section{Technical Challenges Met By SIMI}

The above section describes the user's needs, and how the user
interacts with the system. This section summarizes several categories
of technical challenges the system has to meet in order to support
those user needs. These categories are printed in bold text. Most of
the following topics are described in great detail in the next
chapter.

A fundamental task is \textbf{ink parsing}. While the pen is down, the
system looks for erase gestures. When the user lifts the pen,
non-erase gestures are parsed for corners, and sections of ink are
identified as primitive sub-shapes like lines, curves, and so forth.

SIMI must be able to dependably \textbf{recognize user input}.
Because input is often made quickly and inaccurately, occasional
recognition errors can not be avoided. There are several kinds of
recognized elements. Input might be linework that specifies the
model's geometry. Or, input might be identified as a gesture that
edits the model by removing ink or adding constraints. Last, input
might be as part of a multi-stroke phrase that controls the modeling
environment (e.g. undo/redo, zooming, or panning).

There is one recognizer per recognizable pattern. Each recognizer has
access to the model state, but they do not communicate directly with
each other. Inevitably more than one recognizer will signal a positive
result, so it is necessary for SIMI to \textbf{disambiguate}
contending recognition results. For example, the user may draw two
short strokes that are recognized as both a right angle symbol and a
same-length gesture. To resolve this ambiguity, SIMI uses a series of
tests that involve context (e.g. if the input is correctly positioned
in a corner or not) as well as static precedence rules that defer to
the interpretation that causes the least trouble in the event it is
wrong.

The user's work is stored as a \textbf{data model} consisting of
points, segments (e.g. line, arc), and high-level constraints
(e.g. right angle, same length). SIMI lets the user edit the model to
create, merge, or erase these elements. The \textbf{constraint engine}
is closely associated with the data model. This lets the designer
indicate geometric rules that the system will try to maintains, even
as the user edits the model. SIMI's constraint engine is an iterative,
numerical solver using a relaxation method in the tradition of
Sketchpad~\cite{sutherland-sketchpad}.

When it is time for the user's work to be given to a laser cutter, the
designer asks SIMI to \textbf{generate a cutfile}. This is a 2D vector
graphics file specifying geometry of cutouts. The current
implementation is a rather simplistic ``typewriter'' algorithm---it
uses the bounding box of each cutout, placing one next to the other
from left to right, and moving to the next ``line'' when placing a
piece would extend beyond the material bounds.

\section{Coherent Sketch Based Interaction}

Sketch It, Make It presents a fluid interface for making laser cut
parts. The smooth interaction is made possible by combining many
sketch-based techniques into a set of interaction methods that work
very well together. The fluidity is \textit{not} the result of any one
technique, nor is it simply the result of throwing several existing
methods together.

The interaction techniques offered by SIMI were carefully tuned to
work with one another. Each gesture is as distinct from the others as
possible. This does not completely avoid recognition error but it does
mitigate it because the gestures are not often confused with one
another.

SIMI gives visual feedback when appropriate which helps to resolve
possible conflicts. For example, a selected point will move if a
gesture begins nearby. Without visual feedback that the pen is near
enough, it was easy to inadvertently draw linework when the intention
was to move the point.

The interaction techniques have conservative failure states. The
automatic latching algorithm is a good example. The auto-latcher has
parameters about the distance between points and relative angle of
segments. These parameters were intentionally set to err on the side
of not latching segments together, because the consequences of
latching inappropriately are worse than not latching when the user
wanted. To recover from a missed latch opportunity, SIMI provides a
very simple latching gesture.

SIMI's interaction differs from standard design tools and other sketch
based modeling prototypes in several ways.

\subsection{``The mode problem''}

A traditional design tool like Adobe Illustrator is built around the
concept of input modes such as \textit{select}, \textit{draw line}, or
\textit{fill color}. Users activate modes by selecting a menu option,
clicking an onscreen widget, or pressing a keyboard button. The
program interprets user input in terms of the active tool. Sometimes
users are unaware of which mode the program is in, or are unsure how
to change to the desired mode. Managing modes often introduces
cognitive load by forcing users to think about the tool rather than
their work. This is called ``the mode
problem''~\cite{tesler-mode-problem}.

SIMI's interaction lacks persistent mode. The user can always draw on
any part of the drawing canvas, and the input's meaning is determined
via recognition: an input stroke might be an erasure scribble or a
right angle symbol or a straight line that completes a shape. There is
no `erase mode', no `right angle mode', and no 'draw line mode'. Some
operations, such as flow selection, include transient mode changes
where the meaning of user input is interpreted differently based on
recent interaction. For this reason it is not strictly correct to
label SIMI's interaction as \textit{modeless}.

\subsection{Conversational Interface}

One property that characterizes sketch based systems is \textit{when}
recognition is performed (see
Section~\ref{sec:recognition-when}). Many sketch based design tools
operate in batch mode, where a substantual amount of raw ink is
analyzed at the same time. The rationalle for this approach is that
recognizers have more data (unrecognized ink) to work with and can use
statistical methods to generate the most likely interpretations for
the entire sketch.

SIMI takes a different approach involving short sequences of input
followed by recognition that fix the meaning of input by graphically
representing results. Because the meaning of onscreen elements are
known, the next round of recognition can use that knowledge to provide
unambiguous contextual clues. As the user and system take turns on
such a regular basis, I call this a \textit{conversational
  interface}. The user and the system constantly check each other's
states to ensure that meaning is shared.

\section{Recognition Architecture}
\label{sec:recognition-architecture}

SIMI's recognizers operate at three different times. First,
\textit{Dynamic} recognizers (like Erase) operate while the pen is
down. A second class of recognizers are invoked when the pen is
lifted. If there are positive results from these \textit{Pen Up}
recognizers, action is taken immediately. An example of this kind is
latching. The third kind of recognizer is triggered after a period of
inactivity (currently 1.5 seconds). The user may optionally press a
button with their non-dominant hand to invoke these recognizers on
demand. These recognizers include those that establish constraints
like right angles, or create linework like circles and splines. This
last type is called \textit{Delayed} because it does not happen
immediately after the pen lifts.

\input{fig-recog-arch.tex}

Each recognizer class addresses a different need. Dynamic recognizers
allow the user to make gestures that must be recognized as they are
made, when timing is very important. Pen Up recognizers allow the user
to make distinct gestures that are acted on immediately, eliminating
lag and making the interface seem much more responsive. The Pen Up
recognizers are reserved for common actions that are unlikely to
interrupt the user when their associated actions are taken. By their
nature, both Dynamic and Pen Up recognizers must work on single stroke
gestures. Last, the Delayed recognizers may work on one ore more
strokes, and typically have related actions that might distract the
user if they were invoked right away. The overall recognition
architecture is illustrated in Figure~\ref{fig:recog-arch}.

\subsection{Dynamic Recognizers}
\label{sec:overview-dynamic-recognizers}

Dynamic recognizers use raw pen data that is generated as the user
draws. They are invoked after each new pen movement event, which
typically happen at a rate of once per 15--20 milliseconds. They must
execute very efficiently in order to avoid causing the interface to
seem unresponsive. If the user interface is redrawn at 60 Hz, each
frame must be drawn in less than 16 ms. Therefore it is very important
that all dynamic recognizers execute in much less than this time
period in order to give the graphics subsystem time to draw the
screen.

When a dynamic recognizer finds a positive result, all other Dynamic
recognizers are temporarily turned off, and the associated ink stroke
will not be passed on to the Pen Up recognizers. For example, if the
scribble recognizer determines that the user is erasing, it displays a
visual indication that it recognizers the erasure, and when the user
lifts the pen, it will attempt to erase something. Further, the
Dynamic recognizer might change how the current ink stroke is drawn.

\subsection{Pen Up Recognizers}

If no Dynamic reconizer claimed an ink stroke, it is processed by the
Pen Up recognizers when the user lifts the stylus. The first step is
to parse the raw ink to identify corners and segments. The
implementation details of SIMI's corner finder are given in
Section~\ref{sec:corner-finder}. The Ink Parser supplies a set of
segments, which may be any of the following types: Dots, Lines,
Elliptical Arcs, Splines, Circles, Ellipses, or Blobs (a spline that
starts and ends at a common point).

Pen Up recognizers operate on this set of new segments. Each
recognizer operates independently of the others. They test if segments
comprising the most recent pen stroke match a pattern. It is possible
for several recognizers to positively identify their gesture, but only
one such gesture is valid. If any positive results are found, a
subsequent process resolves conflicts.

The conflicts are mediated in two ways. First, sometimes a gesture
makes more sense than others in context. A context checker will report
how well a gesture matches the current drawing state with a Yes, No,
or Maybe. If only one contending gesture receives a `Yes' vote, the
other interpretations are discarded. Second, if the context checker
can not resolve the problem, then a static rule list is used. This
list ranks each recognizer type, and the interpretation that is
highest on the list is accepted (the rest are rejected).  

The order of this rule list important. Recognizers that edit the model
are lower on the list than recognizers whose effects can be
ignored. For example, a Latch gesture edits the model, while the
gesture to display the Pan/Zoom widget has only a temporary
response. If the wrong interpretation is made, SIMI will err on the
side of the inconsequential or easily recoverable.

If a positive result is found, it is activated without delay. This
means that the action (defined by the gesture) is applied (which is
defined by the context of the gesture). The related action for a Latch
gesture will combine points and possibly destroy and create segments,
which edits the model and causes the graphical representation to
change.

Last, any ink associated with a positive result is removed from the
model and will not be available to the delayed recognizers.

\subsection{Delayed Recognizers}

Delayed recognizers follow a similar process to Pen Up
recognizers. The delayed recognizers are automatically invoked after
the user has not interacted with the system for a short period
(currently 1.5 seconds). The user may optionally speed invocation by
pressing a button with their non-dominant hand.

By this point, any ink that was positively recognized by a Dynamic or
Pen Up recognizer is not available. Every time the pen is lifted, the
ink is processed in the Pen Up recognition step. Any segments that are
not recognized by the Pen Up step are placed in a set of segments for
the Delayed recognizers. This means Delayed recognizers may operate on
segments made in one, two, or (potentially) many more strokes.

Like in the previous recognition step, each Delayed recognizer
operates independently of the others and may produce a positive
result. \textit{Unlike} the previous step, it is possible that several
results are valid, as long as they are composed of different
strokes. This makes it possible, for example, to issue two Right Angle
gestures and a Same Length command in the same batch, all of which can
be recognized. If two potential results involve some of the same
segments, SIMI eploys the same resolution process from the Pen Up
recognizer step.

When conflicts are resolved, there may be zero, one, or more positive
results. The positive results are activated in no particular
order. This could theoretically cause problems (for example if one
action renders another action nonsensical), but this situation has not
been relevant in the current system.

Any segments that are not associated with positive recognizer results
are interpreted as geometry. This is how the user creates linework
that define laser cut parts. This geometry is then included in the
model with definite identities, which are used in later recognition
processes.

\section{Model: Geometry, Constraints, Cutouts}

The data model underlying SIMI is fairly simple. It contains
\textit{named points, segments, constraints, and cutouts}. All these
data are the result of sketch recognition---no raw, unprocessed ink is
stored. \textit{Named points} are time-stamped 2D locations. They are
named because they are given textual labels that allow other entities
to refer to them by name. This makes it easier to debug and to store
the model to disk. 

\textit{Segments} are a patches of linework. They must be one of the
types listed in Table~\ref{tab:segment-types}. All segments are
composed (at least partly) by named points. If the named points change
locations, the segment's geometry is automatically changed as
well. More than one segment can refer to a named point (e.g. if two
lines meet, they share a common point). Some segments are open, while
others are closed. Figure~\ref{fig:linework} illustrates all supported
segment types.

\input{tab-linework.tex} % table
\input{fig-linework.tex} % figure

A \textit{Constraint} establishes geometric relationships among named
points or segments. Constraints refer to named points directly. Like
segments, several constraints can share named
points. Table~\ref{tab:constraints} lists all SIMI's constraint types.

\input{tab-constraints.tex} % table 

The final output of this design tool is a \textit{cutfile} that
contains \textit{Cutouts}. A cutout is a 2D shape defining the
boundary of a part to laser cut. SIMI identifies cutouts automatically
by analyzing the model, searching for closed paths. Cutouts are
graphically shaded. Users may place a cutout in the cutfile region on
the screen to add one or more copies to cutfile.

\subsection{Constraint Solving}

Many user actions trigger the constraint solver. This section
describes how the SIMI's solver works.

Figure~\ref{fig:solving} illustrates the relationship between points,
segments, and constraints. In the first pane, the system has
recognized the user's input as two lines that meet at a common
point. Further, the user has added two constraints indicated the lines
should meet at a right angle, and the lines should be the same length.

Initially, the constraints are not satisfied. The lines meet at about
an 80 degree angle, and the top line is longer than the other. When
constraints are not satisfied, the \textit{constraint solver}
(sometimes called a constraint \textit{engine}) is called on to make
corrections.

SIMI uses an numerical, iterative solver similar to Sutherland's
relaxation method used in Sketchpad~\cite{sutherland-sketchpad}. 

Each iterative step follows the process illustrated in
Figure~\ref{fig:solving}. Before iterating, the constraint engine
determines if it should proceed. It polls each constraint to compute
its error, which is a simple measure of how much change is needed to
satisfy the constraint. Each constraint type calculates its error
differently, so it is not appropriate to directly compare error values
from two kinds of constraints. For example, the ``Same Length''
constraint calculates the mean length of all its segments, and reports
error as the sum of absolute deviation from that mean. A ``Right
Angle'' constraint reports error as the absolute difference between
expected and actual angles. While these numbers are clearly not
directly comparable (radians vs linear distance), they both have the
property of becoming very small when the constraint is reasonably
satisfied.

\input{fig-constraint-solving.tex}

If the total error from all constraints is greater than some
threshold, the solver will proceed, beginning with
Figure~\ref{fig:solving-angle-1}. Each constraint calculates
\textit{change vectors} for each related point. A change vector
describes both a direction and the desired distance to move in that
direction. 

Each constraint computes change vectors differently. For example, the
Right Angle constraint is composed of two \textit{low-level
  constraints} that work together to achieve the desired effect. For
Right Angles, they are Orientation constraints that rotate a line
(e.g. L1) about its midpoint. The high-level constraint coordinates
the low-level constraints on each iteration by supplying a rotation
parameter based on their current and desired angles.

In this case, the low-level constraints operate on L1 (points P1 and
P2) and L2 (P2 and P3). Because P2 is involved in both L1 and L2, it
will be rotated \textit{twice}, as shown in
panel~\textit{\subref{fig:solving-angle-2}}. Named points accumulate
related change vectors. The accumulation process continues until
panel~\textit{\subref{fig:solving-accum-1}}, when all constraints have
computed change vectors. P2 has a total of four---two from the Right
Angle constraint, and two from the Same Length constraint.

The next step is to add each point's change vectors into a
\textit{total change vector}, which describes the direction it could
move (panel~\textit{\subref{fig:solving-accum-2}}).

The last step is to translate each point along its total change vector
(panel~\textit{\subref{fig:solving-total-change}}). It is likely (and
common) that the iterative process will get `stuck' in a loop where
points oscillate between two or more states. To avoid this, SIMI moves
each point a random distance by multiplying its total change vector by
random number between zero and one.

\input{fig-jessica-constraint-error.tex}

Figure~\ref{fig:jessica} illustrates the need for randomness in SIMI's
constraint engine. The user has drawn a cutout that contains 20
vertices, 20 line segments, and several high-level constraints
comprising 45 low-level constraints. When the user moves a corner, the
constraint solver is invoked in order to satisfy the constraints. The
upper right graph shows the solver coming close to a solution fairly
quickly, but getting `stuck' for several thousand iterations, taking
about five seconds to settle down. During this time, the onscreen
representation jitters. In this case, \textit{weak randomness} is
used, and it is applied only to the total change vectors. The effect
of the randomness increases over time. However, this approach was not
satisfactory because it took too long and caused visual jitter.

I handled this problem by modifying the constraint solver to apply
randomness to each individual change vector. For vertices with more
than one change vector, this means the total change vector's direction
is subject to randomness, as well as its magnitude. The results are
satisfactory, as the system of constraints is satisfied in about 1/8
of the number of iterations compared with the weak random case.

